{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, FuncFormatter\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to your .pkl file\n",
    "file_path = 'smac2_training_results.pkl'\n",
    "\n",
    "# Load the data from the .pkl file\n",
    "with open(file_path, 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_names = [\"protoss_5_vs_5\", \"zerg_5_vs_5\", \"terran_5_vs_5\", \"protoss_10_vs_10\", \"zerg_10_vs_10\", \"terran_10_vs_10\", \"protoss_20_vs_20\", \"zerg_20_vs_20\",\n",
    "                    \"terran_20_vs_20\", \"protoss_10_vs_11\", \"zerg_10_vs_11\", \"terran_10_vs_11\", \"protoss_20_vs_23\", \"zerg_20_vs_23\", \"terran_20_vs_23\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, 'loaded_data' contains the data from the .pkl file\n",
    "QMIX_data = {}\n",
    "for key,value in loaded_data.items():\n",
    "    for k2, v2 in value.items():\n",
    "        if k2 == \"QMIX\":\n",
    "            QMIX_data[key] = {k2: v2}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting results for an arbitrary number of steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard as tb\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/hebrect/Documents/DeWet/Meesters/smac_qmix/combining-improvements-in-marl/venv/lib/python3.9/site-packages/tensorboard/backend/event_processing/directory_watcher.py\", line 88, in Load\n",
      "    for event in self._LoadInternal():\n",
      "  File \"/home/hebrect/Documents/DeWet/Meesters/smac_qmix/combining-improvements-in-marl/venv/lib/python3.9/site-packages/tensorboard/backend/event_processing/directory_watcher.py\", line 110, in _LoadInternal\n",
      "    self._InitializeLoader()\n",
      "  File \"/home/hebrect/Documents/DeWet/Meesters/smac_qmix/combining-improvements-in-marl/venv/lib/python3.9/site-packages/tensorboard/backend/event_processing/directory_watcher.py\", line 173, in _InitializeLoader\n",
      "    path = self._GetNextPath()\n",
      "  File \"/home/hebrect/Documents/DeWet/Meesters/smac_qmix/combining-improvements-in-marl/venv/lib/python3.9/site-packages/tensorboard/backend/event_processing/directory_watcher.py\", line 210, in _GetNextPath\n",
      "    for path in io_wrapper.ListDirectoryAbsolute(self._directory)\n",
      "  File \"/home/hebrect/Documents/DeWet/Meesters/smac_qmix/combining-improvements-in-marl/venv/lib/python3.9/site-packages/tensorboard/backend/event_processing/io_wrapper.py\", line 78, in ListDirectoryAbsolute\n",
      "    os.path.join(directory, path) for path in tf.io.gfile.listdir(directory)\n",
      "  File \"/home/hebrect/Documents/DeWet/Meesters/smac_qmix/combining-improvements-in-marl/venv/lib/python3.9/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 896, in listdir\n",
      "    return get_filesystem(dirname).listdir(dirname)\n",
      "  File \"/home/hebrect/Documents/DeWet/Meesters/smac_qmix/combining-improvements-in-marl/venv/lib/python3.9/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 200, in listdir\n",
      "    raise errors.NotFoundError(None, None, \"Could not find directory\")\n",
      "tensorboard.compat.tensorflow_stub.errors.NotFoundError: Could not find directory\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2163667/3912027774.py\", line 72, in <module>\n",
      "    df = get_tb_results(exp, metric_to_plot)\n",
      "  File \"/tmp/ipykernel_2163667/3912027774.py\", line 9, in get_tb_results\n",
      "    event_acc.Reload()\n",
      "  File \"/home/hebrect/Documents/DeWet/Meesters/smac_qmix/combining-improvements-in-marl/venv/lib/python3.9/site-packages/tensorboard/backend/event_processing/event_accumulator.py\", line 343, in Reload\n",
      "    for event in self._generator.Load():\n",
      "  File \"/home/hebrect/Documents/DeWet/Meesters/smac_qmix/combining-improvements-in-marl/venv/lib/python3.9/site-packages/tensorboard/backend/event_processing/directory_watcher.py\", line 92, in Load\n",
      "    raise DirectoryDeletedError(\n",
      "tensorboard.backend.event_processing.directory_watcher.DirectoryDeletedError: Directory ./results/zerg_5_vs_5_19_01_09_23/tb_logs/ has been permanently deleted\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 89\u001b[0m\n\u001b[1;32m     86\u001b[0m     filtered_df \u001b[38;5;241m=\u001b[39m filtered_df\u001b[38;5;241m.\u001b[39miloc[new_indicies]\n\u001b[1;32m     87\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(filtered_df[x_column], filtered_df[y_column], label \u001b[38;5;241m=\u001b[39m exp)\n\u001b[0;32m---> 89\u001b[0m filtered_df_benchmark \u001b[38;5;241m=\u001b[39m df_benchmark_mean[df_benchmark_mean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     91\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(filtered_df_benchmark[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m], filtered_df_benchmark[to_plot], label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbenchmark\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# plt.fill_between(filtered_df_benchmark['step'], filtered_df_benchmark[to_plot] - df_benchmark_std[:ns], filtered_df_benchmark[to_plot] + df_benchmark_std[:ns], alpha=0.2, label='Standard Deviation')\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# plt.plot(filtered_df_noisynet[x_column], filtered_df_noisynet[y_column], label = \"noisynet\")\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# plt.plot(filtered_df_ep_greedy[x_column], filtered_df_ep_greedy[y_column], label = \"epsilon_greedy\")\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_name = \"zerg_5_vs_5\"\n",
    "to_plot = \"mean_test_win_rate\" # mean_test_win_rate mean_test_return\n",
    "metric_to_plot = \"test_avg_win_rate\" #test_avg_win_rate test_mean_reward\n",
    "# df_benchmark = pd.DataFrame(QMIX_data[experiment_name][\"QMIX\"][2])\n",
    "\n",
    "def get_tb_results(experiment_name, get):\n",
    "    logdir = f\"./results/{experiment_name}/tb_logs/\"\n",
    "    event_acc = event_accumulator.EventAccumulator(logdir)\n",
    "    event_acc.Reload()\n",
    "\n",
    "    tags = event_acc.Tags()['scalars']\n",
    "    # get = \"test_avg_win_rate\"\n",
    "    win_rate_tag = next(s for s in tags if get in s)\n",
    "\n",
    "\n",
    "    # # Create an empty DataFrame to store the data\n",
    "    tag_values = [(event.step, event.value) for event in event_acc.Scalars(win_rate_tag)]\n",
    "    df = pd.DataFrame(tag_values, columns=['Step', \"Value\"])\n",
    "    return df\n",
    "\n",
    "def get_means_from_benchmark_result(experiment_name):\n",
    "    dfs = []\n",
    "    for df in range(3):\n",
    "        df_benchmark = pd.DataFrame(QMIX_data[experiment_name][\"QMIX\"][df])\n",
    "        dfs.append(df_benchmark)\n",
    "    \n",
    "    mean_df = sum(dfs)/3\n",
    "    # Get standard deviation:\n",
    "    std_df = pd.concat(dfs).std()\n",
    "\n",
    "    \n",
    "    return mean_df, std_df\n",
    "\n",
    "df_benchmark_mean, df_benchmark_std = get_means_from_benchmark_result(experiment_name)\n",
    "# df_benchmark_mean = pd.DataFrame(QMIX_data[experiment_name][\"QMIX\"][1])\n",
    "# print(df_benchmark_std)\n",
    "\n",
    "# Load CSV file into a Pandas \"DataFrame\"\n",
    "experiments_to_plot = [\"zerg_5_vs_5_22_01_16_00\", \"zerg_5_vs_5_noisy\"]\n",
    "\n",
    "\n",
    "# df_noisynet = get_tb_results(\"smac_experiment_1_14_01_11_56\")\n",
    "# df_ep_greedy = get_tb_results(\"smac_experiment_1_15_01_07_37\")\n",
    "\n",
    "# Set the predetermined number\n",
    "predetermined_number = 10050000\n",
    "\n",
    "\n",
    "# Assuming your CSV has headers, you can reference columns by their names\n",
    "x_column = 'Step'  # Replace with the actual name of the second column\n",
    "y_column = 'Value'   # Replace with the actual name of the third column\n",
    "\n",
    "\n",
    "\n",
    "  # Replace with your predetermined number\n",
    "\n",
    "# Find the maximum step value less than the predetermined number\n",
    "max_step_less_than_predetermined = df_benchmark_mean[df_benchmark_mean['step'] < predetermined_number]['step'].max()\n",
    "\n",
    "# max_step_less_than_predetermined = df_noisynet[df_noisynet['Step'] < predetermined_number]['Step'].max()\n",
    "# max_step_less_than_predetermined = df_ep_greedy[df_ep_greedy['Step'] < predetermined_number]['Step'].max()\n",
    "\n",
    "\n",
    "# Filter the DataFrame based on the condition (step less than max_step_less_than_predetermined)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "max_steps = []\n",
    "dfs = []\n",
    "try:\n",
    "    for exp in experiments_to_plot:\n",
    "        df = get_tb_results(exp, metric_to_plot)\n",
    "        max_step = df[df['Step'] < predetermined_number]['Step'].max()\n",
    "        max_steps.append(max_step)\n",
    "        dfs.append(df)\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "\n",
    "for df, exp in zip(dfs, experiments_to_plot):\n",
    "    filtered_df = df[df['Step'] <= min(max_steps)]\n",
    "    closest_indices = np.searchsorted(filtered_df['Step'], df_benchmark_mean['step'], side=\"left\")\n",
    "    sub_from = closest_indices[-1]\n",
    "    new_indicies = [x - 1 if x == sub_from else x for x in closest_indices]\n",
    "    print(new_indicies)\n",
    "    # print(filtered_df)\n",
    "    filtered_df = filtered_df.iloc[new_indicies]\n",
    "    plt.plot(filtered_df[x_column], filtered_df[y_column], label = exp)\n",
    "\n",
    "filtered_df_benchmark = df_benchmark_mean[df_benchmark_mean['step'] <= min(max_steps)]\n",
    "\n",
    "plt.plot(filtered_df_benchmark['step'], filtered_df_benchmark[to_plot], label = \"benchmark\")\n",
    "\n",
    "# plt.fill_between(filtered_df_benchmark['step'], filtered_df_benchmark[to_plot] - df_benchmark_std[:ns], filtered_df_benchmark[to_plot] + df_benchmark_std[:ns], alpha=0.2, label='Standard Deviation')\n",
    "\n",
    "\n",
    "# filtered_df_noisynet = df_noisynet[df_noisynet['Step'] <= max_step_less_than_predetermined]\n",
    "# filtered_df_ep_greedy = df_ep_greedy[df_ep_greedy['Step'] <= max_step_less_than_predetermined]\n",
    "\n",
    "# Filter my data to only plot points that are very close in x-value to the benchmark\n",
    "# closest_indices = np.searchsorted(filtered_df_noisynet['Step'], filtered_df_benchmark['step'], side=\"left\")\n",
    "# closest_indices = np.searchsorted(filtered_df_ep_greedy['Step'], filtered_df_benchmark['step'], side=\"left\")\n",
    "\n",
    "\n",
    "# filtered_df_noisynet = filtered_df_noisynet.iloc[closest_indices]\n",
    "# filtered_df_ep_greedy = filtered_df_ep_greedy.iloc[closest_indices]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# filtered_df\n",
    "# Plot the data\n",
    "\n",
    "# plt.plot(filtered_df_benchmark['step'], filtered_df_benchmark[to_plot], label = \"benchmark\")\n",
    "# plt.plot(filtered_df_noisynet[x_column], filtered_df_noisynet[y_column], label = \"noisynet\")\n",
    "# plt.plot(filtered_df_ep_greedy[x_column], filtered_df_ep_greedy[y_column], label = \"epsilon_greedy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f\"{experiment_name}: {to_plot}\")\n",
    "plt.grid(alpha = 0.3)\n",
    "\n",
    "# Plot my results\n",
    "# # Create a scatter plot\n",
    "\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(x_column)\n",
    "plt.ylabel(y_column)\n",
    "plt.title('Plot of Mean Win Rate vs {}'.format(x_column))\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting all results for QMIX seed 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types = [\"mean_test_return\", \"mean_test_win_rate\"]\n",
    "# for name in experiment_names:\n",
    "#     df = pd.DataFrame(QMIX_data[name][\"QMIX\"][0])\n",
    "    \n",
    "#     for type in types:\n",
    "#         # Assuming df is your DataFrame\n",
    "#         # Replace 'col1' and 'col2' with your actual column names\n",
    "#         plt.figure(figsize=(16,9))\n",
    "\n",
    "#         # Plotting\n",
    "#         plt.plot(df['step'], df[type], label = type)\n",
    "\n",
    "#         # Adding labels and title\n",
    "#         plt.xlabel('Step')\n",
    "#         plt.ylabel(type)\n",
    "#         plt.title(f\"{name}: {type}\")\n",
    "#         plt.grid(alpha = 0.3)\n",
    "#         plt.legend()\n",
    "\n",
    "#         ax = plt.gca()\n",
    "#         ax.xaxis.set_major_locator(MultipleLocator(1000000))\n",
    "#         ax.xaxis.set_major_formatter(FuncFormatter(lambda x, _: int(x/1000000)))\n",
    "\n",
    "#         # Display the plot\n",
    "#         plt.savefig(f\"figures/{name}.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting mean of benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_name = \"protoss_10_vs_11\"\n",
    "# to_plot = \"mean_test_win_rate\" # mean_test_win_rate mean_test_return\n",
    "# # df_benchmark = pd.DataFrame(QMIX_data[experiment_name][\"QMIX\"][2])\n",
    "\n",
    "\n",
    "def get_means_from_benchmark_result(experiment_name):\n",
    "    dfs = []\n",
    "    for df in range(3):\n",
    "        df_benchmark = pd.DataFrame(QMIX_data[experiment_name][\"QMIX\"][df])\n",
    "        dfs.append(df_benchmark)\n",
    "    \n",
    "    mean_df = sum(dfs)/3\n",
    "    # Get standard deviation:\n",
    "    std_df = pd.concat(dfs).std()\n",
    "\n",
    "    \n",
    "    return mean_df, std_df\n",
    "\n",
    "mean_df,std_df = get_means_from_benchmark_result(experiment_name)\n",
    "x = mean_df.index \n",
    "plt.plot(x, mean_df, label='Mean')\n",
    "plt.fill_between(x, mean_df - std_df, mean_df + std_df, alpha=0.2, label='Standard Deviation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting my own results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmark = pd.DataFrame(QMIX_data[experiment_name][\"QMIX\"][2])\n",
    "df_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
